{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f39c42",
   "metadata": {},
   "source": [
    "## 1. Load All CSV Files from DemographicData Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a48372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "data_dir = '../DemographicData/'\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = glob.glob(os.path.join(data_dir, '*.csv'))\n",
    "\n",
    "print(f\"Total CSV files found: {len(csv_files)}\")\n",
    "print(f\"\\nFirst 10 files:\")\n",
    "for i, file in enumerate(csv_files[:10], 1):\n",
    "    print(f\"{i}. {os.path.basename(file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22697a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files and combine them\n",
    "print(\"Loading all CSV files...\")\n",
    "print(\"This may take a few moments...\\n\")\n",
    "\n",
    "df_list = []\n",
    "failed_files = []\n",
    "\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file, low_memory=False)\n",
    "        df_list.append(df_temp)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Loaded {i}/{len(csv_files)} files...\")\n",
    "    except Exception as e:\n",
    "        failed_files.append((file, str(e)))\n",
    "        print(f\"Failed to load {os.path.basename(file)}: {e}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Successfully loaded {len(df_list)} files\")\n",
    "print(f\"✗ Failed to load {len(failed_files)} files\")\n",
    "print(f\"\\nTotal records loaded: {len(df_raw):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead4b6d",
   "metadata": {},
   "source": [
    "## 2. Verify Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Shape:\")\n",
    "print(f\"Rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Columns: {df_raw.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_raw.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for expected columns\n",
    "expected_columns = ['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_']\n",
    "actual_columns = df_raw.columns.tolist()\n",
    "\n",
    "print(\"Column Verification:\")\n",
    "print(\"=\" * 50)\n",
    "for col in expected_columns:\n",
    "    if col in actual_columns:\n",
    "        print(f\"✓ {col} - Present\")\n",
    "    else:\n",
    "        print(f\"✗ {col} - Missing\")\n",
    "\n",
    "# Check for extra columns\n",
    "extra_cols = set(actual_columns) - set(expected_columns)\n",
    "if extra_cols:\n",
    "    print(f\"\\nExtra columns found: {list(extra_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85467e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "df_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8890ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "missing_counts = df_raw.isnull().sum()\n",
    "missing_percent = (df_raw.isnull().sum() / len(df_raw)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df_raw.columns,\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing %': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"✓ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c50ef7",
   "metadata": {},
   "source": [
    "## 3. Date Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b852b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Check current date format\n",
    "print(\"Sample date values before standardization:\")\n",
    "print(df['date'].head(10))\n",
    "print(f\"\\nDate data type: {df['date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime format\n",
    "print(\"Converting dates to standardized format...\")\n",
    "\n",
    "# Try different date formats\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        # Try DD-MM-YYYY format first\n",
    "        return pd.to_datetime(date_str, format='%d-%m-%Y', errors='coerce')\n",
    "    except:\n",
    "        try:\n",
    "            # Try automatic parsing\n",
    "            return pd.to_datetime(date_str, errors='coerce')\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# Check for date parsing failures\n",
    "date_nulls = df['date'].isnull().sum()\n",
    "print(f\"\\nDate parsing results:\")\n",
    "print(f\"Successfully parsed: {len(df) - date_nulls:,} ({((len(df) - date_nulls)/len(df)*100):.2f}%)\")\n",
    "print(f\"Failed to parse: {date_nulls:,} ({(date_nulls/len(df)*100):.2f}%)\")\n",
    "\n",
    "# Display sample parsed dates\n",
    "print(\"\\nSample standardized dates:\")\n",
    "print(df['date'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract additional date features\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year_month'] = df['date'].dt.to_period('M')\n",
    "df['day'] = df['date'].dt.day\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "\n",
    "print(\"Date features extracted:\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nUnique years: {sorted(df['year'].dropna().unique())}\")\n",
    "print(f\"Unique months: {sorted(df['month'].dropna().unique())}\")\n",
    "print(f\"\\nSample with date features:\")\n",
    "df[['date', 'year', 'month', 'quarter', 'year_month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cd11a",
   "metadata": {},
   "source": [
    "## 4. District-Pincode Consistency Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text columns\n",
    "print(\"Standardizing state and district names...\")\n",
    "\n",
    "# Convert to title case and strip whitespace\n",
    "df['state'] = df['state'].astype(str).str.strip().str.title()\n",
    "df['district'] = df['district'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Convert pincode to string and handle invalid values\n",
    "df['pincode'] = df['pincode'].astype(str).str.strip()\n",
    "\n",
    "print(\"✓ Text standardization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values check\n",
    "print(\"Geographic Data Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Unique States: {df['state'].nunique()}\")\n",
    "print(f\"Unique Districts: {df['district'].nunique()}\")\n",
    "print(f\"Unique Pincodes: {df['pincode'].nunique()}\")\n",
    "\n",
    "print(\"\\nTop 10 States by record count:\")\n",
    "print(df['state'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create district-pincode mapping for consistency check\n",
    "district_pincode_map = df.groupby('district')['pincode'].apply(lambda x: set(x)).to_dict()\n",
    "\n",
    "print(f\"Total district-pincode mappings: {len(district_pincode_map)}\")\n",
    "print(\"\\nSample district-pincode relationships:\")\n",
    "for i, (district, pincodes) in enumerate(list(district_pincode_map.items())[:5]):\n",
    "    print(f\"{i+1}. {district}: {len(pincodes)} unique pincodes\")\n",
    "    print(f\"   Sample pincodes: {list(pincodes)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid pincode values\n",
    "print(\"Pincode Validation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Valid Indian pincodes are 6-digit numbers\n",
    "df['pincode_valid'] = df['pincode'].str.match(r'^\\d{6}$')\n",
    "\n",
    "valid_pincodes = df['pincode_valid'].sum()\n",
    "invalid_pincodes = len(df) - valid_pincodes\n",
    "\n",
    "print(f\"Valid pincodes (6 digits): {valid_pincodes:,} ({(valid_pincodes/len(df)*100):.2f}%)\")\n",
    "print(f\"Invalid pincodes: {invalid_pincodes:,} ({(invalid_pincodes/len(df)*100):.2f}%)\")\n",
    "\n",
    "if invalid_pincodes > 0:\n",
    "    print(\"\\nSample invalid pincodes:\")\n",
    "    print(df[~df['pincode_valid']]['pincode'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf45f82",
   "metadata": {},
   "source": [
    "## 5. Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive missing value analysis\n",
    "print(\"Detailed Missing Value Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in df.columns:\n",
    "    null_count = df[col].isnull().sum()\n",
    "    null_percent = (null_count / len(df)) * 100\n",
    "    \n",
    "    if null_count > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Missing: {null_count:,} ({null_percent:.2f}%)\")\n",
    "        \n",
    "        # Show sample of rows with missing values\n",
    "        if null_count <= 10:\n",
    "            print(f\"  Sample rows: {df[df[col].isnull()].index.tolist()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"Handling Missing Values:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Remove rows with missing dates (critical field)\n",
    "rows_before = len(df)\n",
    "df = df[df['date'].notna()]\n",
    "rows_removed_date = rows_before - len(df)\n",
    "print(f\"Removed {rows_removed_date:,} rows with missing dates\")\n",
    "\n",
    "# Fill missing demographic values with 0 (reasonable assumption for update counts)\n",
    "df['demo_age_5_17'] = df['demo_age_5_17'].fillna(0)\n",
    "df['demo_age_17_'] = df['demo_age_17_'].fillna(0)\n",
    "print(\"Filled missing demographic values with 0\")\n",
    "\n",
    "# Handle missing geographic data\n",
    "df['state'] = df['state'].fillna('Unknown')\n",
    "df['district'] = df['district'].fillna('Unknown')\n",
    "df['pincode'] = df['pincode'].fillna('000000')\n",
    "print(\"Filled missing geographic data with placeholders\")\n",
    "\n",
    "print(f\"\\n✓ Final dataset size: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702fc4f",
   "metadata": {},
   "source": [
    "## 6. Data Type Conversion & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02db5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert demographic columns to numeric\n",
    "print(\"Converting demographic columns to numeric...\")\n",
    "\n",
    "df['demo_age_5_17'] = pd.to_numeric(df['demo_age_5_17'], errors='coerce').fillna(0).astype(int)\n",
    "df['demo_age_17_'] = pd.to_numeric(df['demo_age_17_'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "print(\"✓ Demographic columns converted to integers\")\n",
    "\n",
    "# Display data types\n",
    "print(\"\\nFinal Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative values (data quality check)\n",
    "print(\"Data Quality Checks:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "negative_child = (df['demo_age_5_17'] < 0).sum()\n",
    "negative_adult = (df['demo_age_17_'] < 0).sum()\n",
    "\n",
    "print(f\"Negative values in demo_age_5_17: {negative_child}\")\n",
    "print(f\"Negative values in demo_age_17_: {negative_adult}\")\n",
    "\n",
    "# Remove negative values if any\n",
    "if negative_child > 0 or negative_adult > 0:\n",
    "    df = df[(df['demo_age_5_17'] >= 0) & (df['demo_age_17_'] >= 0)]\n",
    "    print(f\"✓ Removed rows with negative values\")\n",
    "\n",
    "print(f\"\\nFinal clean dataset: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30412639",
   "metadata": {},
   "source": [
    "## 7. Monthly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a89f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monthly aggregated dataset\n",
    "print(\"Creating monthly aggregated dataset...\")\n",
    "\n",
    "# Aggregate by year_month, state, district, pincode\n",
    "df_monthly = df.groupby(['year_month', 'state', 'district', 'pincode']).agg({\n",
    "    'demo_age_5_17': 'sum',\n",
    "    'demo_age_17_': 'sum',\n",
    "    'date': 'count'  # Count of records (transactions)\n",
    "}).reset_index()\n",
    "\n",
    "df_monthly.rename(columns={'date': 'record_count'}, inplace=True)\n",
    "\n",
    "print(f\"✓ Monthly aggregation complete\")\n",
    "print(f\"Original records: {len(df):,}\")\n",
    "print(f\"Monthly aggregated records: {len(df_monthly):,}\")\n",
    "print(f\"\\nSample monthly data:\")\n",
    "df_monthly.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11731a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create district-level monthly aggregation (for analysis)\n",
    "df_monthly_district = df.groupby(['year_month', 'state', 'district']).agg({\n",
    "    'demo_age_5_17': 'sum',\n",
    "    'demo_age_17_': 'sum',\n",
    "    'date': 'count',\n",
    "    'pincode': 'nunique'  # Number of unique pincodes\n",
    "}).reset_index()\n",
    "\n",
    "df_monthly_district.rename(columns={\n",
    "    'date': 'record_count',\n",
    "    'pincode': 'pincode_count'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"District-level monthly records: {len(df_monthly_district):,}\")\n",
    "print(f\"\\nSample district monthly data:\")\n",
    "df_monthly_district.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05cc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state-level monthly aggregation\n",
    "df_monthly_state = df.groupby(['year_month', 'state']).agg({\n",
    "    'demo_age_5_17': 'sum',\n",
    "    'demo_age_17_': 'sum',\n",
    "    'date': 'count',\n",
    "    'district': 'nunique',\n",
    "    'pincode': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "df_monthly_state.rename(columns={\n",
    "    'date': 'record_count',\n",
    "    'district': 'district_count',\n",
    "    'pincode': 'pincode_count'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"State-level monthly records: {len(df_monthly_state):,}\")\n",
    "print(f\"\\nSample state monthly data:\")\n",
    "df_monthly_state.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942aec3",
   "metadata": {},
   "source": [
    "## 8. Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived features to monthly datasets\n",
    "print(\"Creating derived features...\")\n",
    "\n",
    "# For pincode-level data\n",
    "df_monthly['total_updates'] = df_monthly['demo_age_5_17'] + df_monthly['demo_age_17_']\n",
    "df_monthly['child_update_share'] = (df_monthly['demo_age_5_17'] / \n",
    "                                     (df_monthly['total_updates'] + 0.0001)) * 100  # Avoid division by zero\n",
    "\n",
    "# For district-level data\n",
    "df_monthly_district['total_updates'] = df_monthly_district['demo_age_5_17'] + df_monthly_district['demo_age_17_']\n",
    "df_monthly_district['child_update_share'] = (df_monthly_district['demo_age_5_17'] / \n",
    "                                              (df_monthly_district['total_updates'] + 0.0001)) * 100\n",
    "\n",
    "# For state-level data\n",
    "df_monthly_state['total_updates'] = df_monthly_state['demo_age_5_17'] + df_monthly_state['demo_age_17_']\n",
    "df_monthly_state['child_update_share'] = (df_monthly_state['demo_age_5_17'] / \n",
    "                                           (df_monthly_state['total_updates'] + 0.0001)) * 100\n",
    "\n",
    "print(\"✓ Derived features created:\")\n",
    "print(\"  - total_updates\")\n",
    "print(\"  - child_update_share\")\n",
    "\n",
    "print(\"\\nSample with derived features:\")\n",
    "df_monthly_district[['year_month', 'state', 'district', 'demo_age_5_17', \n",
    "                     'demo_age_17_', 'total_updates', 'child_update_share']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b952af4",
   "metadata": {},
   "source": [
    "## 9. Final Data Summary & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL DATA PREPARATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. RAW DATASET (Daily Records):\")\n",
    "print(f\"   Total Records: {len(df):,}\")\n",
    "print(f\"   Date Range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"   Unique States: {df['state'].nunique()}\")\n",
    "print(f\"   Unique Districts: {df['district'].nunique()}\")\n",
    "print(f\"   Unique Pincodes: {df['pincode'].nunique()}\")\n",
    "\n",
    "print(\"\\n2. MONTHLY AGGREGATED DATASETS:\")\n",
    "print(f\"   Pincode-level: {len(df_monthly):,} records\")\n",
    "print(f\"   District-level: {len(df_monthly_district):,} records\")\n",
    "print(f\"   State-level: {len(df_monthly_state):,} records\")\n",
    "\n",
    "print(\"\\n3. DEMOGRAPHIC STATISTICS:\")\n",
    "print(f\"   Total child updates (5-17): {df['demo_age_5_17'].sum():,}\")\n",
    "print(f\"   Total adult updates (17+): {df['demo_age_17_'].sum():,}\")\n",
    "print(f\"   Total updates: {(df['demo_age_5_17'].sum() + df['demo_age_17_'].sum()):,}\")\n",
    "\n",
    "overall_child_share = (df['demo_age_5_17'].sum() / \n",
    "                       (df['demo_age_5_17'].sum() + df['demo_age_17_'].sum()) * 100)\n",
    "print(f\"   Overall child update share: {overall_child_share:.2f}%\")\n",
    "\n",
    "print(\"\\n4. DATA QUALITY:\")\n",
    "print(f\"   Rows with valid dates: {(~df['date'].isnull()).sum():,}\")\n",
    "print(f\"   Rows with valid pincodes: {df['pincode_valid'].sum():,}\")\n",
    "print(f\"   Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "print(\"\\nSaving processed datasets...\")\n",
    "\n",
    "output_dir = '../outputs/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(f'{output_dir}df_clean_daily.csv', index=False)\n",
    "df_monthly.to_csv(f'{output_dir}df_monthly_pincode.csv', index=False)\n",
    "df_monthly_district.to_csv(f'{output_dir}df_monthly_district.csv', index=False)\n",
    "df_monthly_state.to_csv(f'{output_dir}df_monthly_state.csv', index=False)\n",
    "\n",
    "print(\"✓ Saved CSV files:\")\n",
    "print(f\"  - df_clean_daily.csv ({len(df):,} rows)\")\n",
    "print(f\"  - df_monthly_pincode.csv ({len(df_monthly):,} rows)\")\n",
    "print(f\"  - df_monthly_district.csv ({len(df_monthly_district):,} rows)\")\n",
    "print(f\"  - df_monthly_state.csv ({len(df_monthly_state):,} rows)\")\n",
    "\n",
    "# Also save as pickle for faster loading\n",
    "df.to_pickle(f'{output_dir}df_clean_daily.pkl')\n",
    "df_monthly.to_pickle(f'{output_dir}df_monthly_pincode.pkl')\n",
    "df_monthly_district.to_pickle(f'{output_dir}df_monthly_district.pkl')\n",
    "df_monthly_state.to_pickle(f'{output_dir}df_monthly_state.pkl')\n",
    "\n",
    "print(\"\\n✓ Saved pickle files for faster loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of final cleaned data\n",
    "print(\"\\nSample of cleaned daily data:\")\n",
    "display(df[['date', 'year_month', 'state', 'district', 'pincode', \n",
    "            'demo_age_5_17', 'demo_age_17_']].head(10))\n",
    "\n",
    "print(\"\\nSample of monthly district data:\")\n",
    "display(df_monthly_district[['year_month', 'state', 'district', \n",
    "                             'demo_age_5_17', 'demo_age_17_', \n",
    "                             'total_updates', 'child_update_share']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ea467",
   "metadata": {},
   "source": [
    "## ✅ Data Preparation Complete!\n",
    "\n",
    "### Summary of Accomplishments:\n",
    "\n",
    "1. ✓ **Loaded all CSV files** from DemographicData folder\n",
    "2. ✓ **Verified data structure** - confirmed all expected columns present\n",
    "3. ✓ **Date standardization** - converted to datetime format and extracted features\n",
    "4. ✓ **District-pincode consistency** - standardized text, validated pincodes\n",
    "5. ✓ **Missing value handling** - filled/removed as appropriate\n",
    "6. ✓ **Monthly aggregation** - created pincode, district, and state-level datasets\n",
    "7. ✓ **Derived features** - calculated total_updates and child_update_share\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to univariate analysis\n",
    "- Begin exploratory visualization\n",
    "- Calculate baseline statistics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
